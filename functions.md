# üìö Documentaci√≥n de Funciones

## **Funci√≥n 1** `Image.convert`

```python
def convert(mode: str | None = None, 
           matrix: tuple[float, ...] | None = None, 
           dither: Dither | None = None, 
           palette: Palette = Palette.WEB, 
           colors: int = 256) ‚Üí Image
```

### Par√°metros

- **`mode`**: Este es el par√°metro m√°s importante y especifica a qu√© **[modo de color](https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes)** quieres convertir la imagen.

- **`matrix`**: Es opcional y se puede utilizar para especificar una matriz de transformaci√≥n personalizada. Generalmente, no se usa a menos que necesites una conversi√≥n espec√≠fica y personalizada de color.

- **`dither`**: Controla la cantidad de dithering (difuminado de colores) aplicada durante la conversi√≥n. [Los m√©todos disponibles](https://pillow.readthedocs.io/en/stable/reference/Image.html#dither-modes) son `Dither.NONE` o `Dither.FLOYDSTEINBERG` (por defecto). Tenga en cuenta que esto no se utiliza cuando se suministra la matriz.

- **`palette`**: Es opcional, relevante solo cuando se convierte a modo P (paleta de colores) debido a que define c√≥mo se debe crear la paleta. [Las paletas](https://pillow.readthedocs.io/en/stable/reference/Image.html#palettes) disponibles son `Palette.WEB` o `Palette.ADAPTIVE`.

- **`colors`**: Es opcional y se usa para definir el n√∫mero de colores cuando se est√° convirtiendo a una imagen en modo paleta. Por defecto es 256.

---

## **Funci√≥n 2** `bilateralFilter`

```python
def bilateralFilter(src: MatLike, 
                   d: int, 
                   sigmaColor: float, 
                   sigmaSpace: float) -> MatLike
```

### Par√°metros

- **`src`**: Im√°gen a aplicar filtro.

- **`d`**: Di√°metro de cada vecindario de p√≠xeles utilizado durante el filtrado. Si no es positivo, se calcula a partir de `sigmaSpace`.

- **`sigmaColor`**: Filtro sigma en el espacio de color. Un valor mayor de este par√°metro significa que los colores m√°s distantes dentro del vecindario del p√≠xel se mezclar√°n entre s√≠, resultando en √°reas m√°s grandes de color semi-igual.

- **`sigmaSpace`**: Filtro sigma en el espacio de coordenadas. Un valor mayor de este par√°metro significa que los p√≠xeles m√°s alejados se influir√°n mutuamente, siempre que sus colores sean lo suficientemente cercanos. Cuando `d > 0`, especifica el tama√±o del vecindario independientemente de `sigmaSpace`. De lo contrario, `d` es proporcional a `sigmaSpace`.

---

## **Funci√≥n 3** `auto_canny`

```python
def auto_canny(image: MatLike, sigma: float = 0.33)
```

### Par√°metros

- **`image`**: Im√°gen a aplicar filtro.

- **`sigma`**: Argumento opcional, puede utilizarse para variar los umbrales porcentuales que se determinan bas√°ndose en estad√≠sticas simples. Con valor por defecto de 0.33.

---

## **Funci√≥n 4** `findContours`

```python
def findContours(image: MatLike, 
                mode: int, 
                method: int, 
                contours: Sequence[MatLike] | None = None, 
                hierarchy: MatLike | None = None, 
                offset: Point = (0,0))
```

### Par√°metros

- **`image`**: Imagen donde se buscar√°n los contornos.

- **`mode`**: El [modo de recuperaci√≥n de contornos](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71) que define la jerarqu√≠a de los mismos. Los valores posibles son:
  - **`RETR_EXTERNAL`**: Este m√©todo recupera solo los contornos exteriores. Es √∫til cuando solo te interesa detectar los l√≠mites externos de los objetos en la imagen, de modo que si hay un contorno que encierra a otro (como c√≠rculos conc√©ntricos), s√≥lo se da el m√°s exterior.
  - **`RETR_LIST`**: Este m√©todo recupera todos los contornos sin establecer relaciones jer√°rquicas. Es √∫til cuando necesitas todos los contornos, pero no te importa la estructura jer√°rquica entre ellos.
  - **`RETR_TREE`**: Este m√©todo recupera todos los contornos y reconstruye una jerarqu√≠a completa de contornos anidados. Es √∫til cuando necesitas entender la relaci√≥n entre contornos internos y externos, como en la detecci√≥n de objetos dentro de otros objetos.
  - **`RETR_CCOMP`**: Similar a `RETR_TREE`, pero solo crea relaciones jer√°rquicas entre contornos de primer y segundo nivel. Es √∫til cuando necesitas una jerarqu√≠a limitada a dos niveles.

- **`method`**: El [m√©todo de aproximaci√≥n de contornos](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga4303f45752694956374734a03c54d5ff) que define c√≥mo se representan los contornos. Los valores posibles son:
  - **`CHAIN_APPROX_NONE`**: Guarda todos los puntos del contorno. Es la m√°s precisa, pero puede generar muchos puntos, lo que aumenta el procesamiento.
  - **`CHAIN_APPROX_SIMPLE`**: Reduce la cantidad de puntos guardando solo los puntos esenciales que forman el contorno, eliminando los puntos redundantes. Esto simplifica mucho el contorno y es √∫til para la mayor√≠a de los casos.
  - **`CHAIN_APPROX_TC89_L1`** y **`CHAIN_APPROX_TC89_KCOS`**: Son m√©todos de aproximaci√≥n de contornos que utilizan el algoritmo de Teh-Chin, que proporciona una mayor precisi√≥n y puede ser √∫til en casos espec√≠ficos donde se necesita una mayor exactitud.

- **`contours`**: Opcional. Una lista de contornos detectados, donde cada contorno es una lista de puntos. Si se proporciona, se llena con los contornos detectados.

- **`hierarchy`**: Opcional. Una matriz que describe la relaci√≥n jer√°rquica entre los contornos. Es √∫til para entender c√≥mo se relacionan los contornos entre s√≠ (por ejemplo, contornos internos dentro de contornos externos).

- **`offset`**: Opcional. Un desplazamiento para ajustar las coordenadas de los contornos. √ötil si se est√° trabajando con recortes de im√°genes y se necesita ajustar las coordenadas de los contornos a la imagen original.

---

## **Funci√≥n 5** `four_point_transform`

```python
def four_point_transform(image: MatLike, pts: List[Point])
```

### Par√°metros

- **`image`**: Im√°gen a obtener sub-im√°gen.

- **`pts`**: Lista de los 4 puntos que contienen la sub-im√°gen deseada.

---

## **Funci√≥n 6** `crop`

```python
def crop(box: tuple[float, float, float, float] | None = None)
```

### Par√°metros

- **`box`**: Opcional, lista de coordenadas para hacer el recorte, el orden es `[x0, y0, x1, y1]`. Por defecto es `None`.

---

## **Funci√≥n 7** `tf.keras.layers.Input`

```python
tf.keras.layers.Input(shape: tuple[int] = None, **kwargs)
```

### Par√°metros

- **`shape`**: Opcional, tupla de enteros para definir la forma de las entradas. S√≠ no se asigna, se interpretar√° que no se conoce las dimensiones y puede variar.

---

## **Funci√≥n 8** Data augmented

### Par√°metro com√∫n

- **`fill_value`**: Valor num√©rico entre 0 y 255 con el que se rellenar√°n los l√≠mites cuando se usa `constant` como m√©todo de relleno.

- **`fill_mode`**: Forma en que se rellenan los l√≠mites seg√∫n el modo dado, entre ellos:
  - **`reflect`**: Valor por defecto, refleja el borde del √∫ltimo p√≠xel de la imagen para llenar los vac√≠os.
  - **`constant`**: Los l√≠mites se rellenan con un mismo valor (color) especificado por `fill_value`.
  - **`wrap`**: La entrada se extiende envolviendo hasta el borde opuesto.
  - **`nearest`**: La entrada se extiende por el p√≠xel m√°s cercano.

### `tf.keras.layers.RandomTranslation`

```python
tf.keras.layers.RandomTranslation(height_factor: float | tuple[float, float], 
                                 width_factor: float | tuple, 
                                 fill_mode: str = 'reflect', 
                                 fill_value: float = 0.0, 
                                 **kwargs)
```

#### Par√°metros

- **`height_factor`**: Un n√∫mero o tupla de n√∫meros con valores de entre 0 y 1, que representa el l√≠mite inferior y superior para el desplazamiento vertical de manera porcentual. Un valor negativo significa desplazar la imagen hacia arriba, mientras que un valor positivo significa desplazarla hacia abajo. Si el factor es un n√∫mero, este se usar√° para ambos l√≠mites. Ejemplo: `height_factor = .2` dar√° como resultado `[-20%, +20%]`.

- **`width_factor`**: Un n√∫mero o tupla de n√∫meros con valores de entre 0 y 1, que representa el l√≠mite inferior y superior para el desplazamiento horizontal de manera porcentual. Un valor negativo significa desplazar la imagen hacia la izquierda, mientras que un valor positivo significa desplazarla hacia la derecha.

### `tf.keras.layers.RandomRotation`

```python
tf.keras.layers.RandomRotation(factor: float | tuple[float, float], 
                              fill_mode: str = 'reflect', 
                              fill_value: float = 0.0, 
                              **kwargs)
```

#### Par√°metros

- **`factor`**: Un n√∫mero representado como fracci√≥n de 2œÄ, o una tupla de tama√±o 2 que representa los l√≠mites inferior y superior de la rotaci√≥n en sentido horario y antihorario. Un valor positivo significa girar en el sentido contrario a las agujas del reloj, mientras que uno negativo significa girar en el sentido de las agujas del reloj.

### `tf.keras.layers.RandomZoom`

```python
tf.keras.layers.RandomZoom(height_factor: float | tuple[float, float], 
                          fill_mode: str ='reflect', 
                          fill_value: float = 0.0, 
                          **kwargs)
```

#### Par√°metros

- **`height_factor`**: Un n√∫mero representado como fracci√≥n del valor, o una tupla de tama√±o 2 que representa el l√≠mite inferior y superior para el zoom (aumento) vertical. Cuando se representa como un √∫nico n√∫mero, este valor se utiliza tanto para el l√≠mite superior como para el inferior. Un valor positivo significa alejar, mientras que un valor negativo significa acercar.

### `tf.keras.layers.RandomBrightness`

```python
tf.keras.layers.RandomBrightness(factor: float | tuple[float, float], 
                                **kwargs)
```

#### Par√°metros

- **`factor`**: N√∫mero o una lista/tupla de 2 n√∫meros entre -1.0 y 1.0. El factor se utiliza para determinar el l√≠mite inferior y superior del ajuste del brillo. Se elegir√° aleatoriamente un valor entre los l√≠mites. Cuando se elige -1.0, la imagen de salida ser√° negra, y cuando se elige 1.0, la imagen ser√° totalmente blanca.

### `tf.keras.layers.RandomContrast`

```python
tf.keras.layers.RandomContrast(factor: float | tuple[float, float], 
                              **kwargs)
```

#### Par√°metros

- **`factor`**: N√∫mero positivo representado como fracci√≥n del valor, o una tupla de tama√±o 2 que representa los l√≠mites inferior y superior. Cuando se representa como un √∫nico n√∫mero, este valor se utiliza tanto para el l√≠mite superior como para el inferior. El factor de contraste se elegir√° aleatoriamente entre `[1.0 - inferior, 1.0 + superior]`. Para cualquier p√≠xel `x` del canal, la salida ser√° `(x - media) * factor + media`, donde `media` es el valor medio del canal.

---

## **Funci√≥n 9** `tf.keras.layers.Rescaling`

```python
tf.keras.layers.Rescaling(scale: float, 
                         offset: float, 
                         **kwargs)
```

### Par√°metros

- **`scale`**: La escala a aplicar a las entradas. Ejemplo: Para reescalar una entrada en el rango `[0, 255]` para que est√© en el rango `[0, 1]`, pasar√≠a `scale = 1./255` y para reescalar una entrada en el rango `[0, 255]` para que est√© en el rango `[-1, 1]`, se pasar√≠a `scale = 1./127.5` y `offset = -1`.

- **`offset`**: El desplazamiento a aplicar a las entradas.

---

## **Funci√≥n 10** `tf.keras.layers.Conv2D`

```python
tf.keras.layers.Conv2D(filters: int, 
                      kernel_size: int | tuple[int, int], 
                      activation: str | any, 
                      **kwargs)
```

### Par√°metros

- **`filters`**: N√∫mero de filtros. Cada filtro representa una caracter√≠stica que puede variar desde bordes y texturas hasta patrones m√°s complejos; a mayor cantidad de filtros, el modelo puede aprender caracter√≠sticas m√°s detalladas, aunque con un mayor costo computacional.

- **`kernel_size`**: Tama√±o del filtro (ancho y alto), que determina el "vecindario" de la entrada que cada filtro abarca en cada paso. S√≠ solo se pasa un √∫nico valor, se usar√° el mismo para el ancho y alto. Los filtros peque√±os (como 3x3) son comunes, ya que capturan bien los patrones locales y mantienen el costo computacional bajo.

- **`activation`**: Funci√≥n de activaci√≥n, que define c√≥mo se manejar√°n los valores en cada paso. Entre las opciones, se encuentran `relu`, `leaky relu`, entre otras.

---

## **Funci√≥n 11** `tf.keras.layers.MaxPool2D`

```python
tf.keras.layers.MaxPool2D(pool_size: int | tuple[int, int] = (2, 2), 
                         **kwargs)
```

### Par√°metros

- **`pool_size`**: N√∫mero entero o tupla de 2 enteros, factores por los que reducir la escala `(dim1, dim2)`. Si s√≥lo se especifica un entero, se utilizar√° la misma longitud de ventana para todas las dimensiones.

---

## **Funci√≥n 12** `tf.keras.layers.Dense`

```python
tf.keras.layers.Dense(units: int, 
                     activation str | any = None, 
                     **kwargs)
```

### Par√°metros

- **`units`**: N√∫mero entero positivo, para indicar el n√∫mero de neuronas que tendr√° la capa.

- **`activation`**: Funci√≥n de activaci√≥n.

---

## **Funci√≥n 13** `tf.keras.layers.Dropout`

```python
tf.keras.layers.Dropout(rate: float, **kwargs)
```

### Par√°metros

- **`rate`**: N√∫mero entre 0 y 1. Fracci√≥n de las unidades de entrada que hay que dejar caer.

---

## **Funci√≥n 14** `compile`

```python
def compile(optimizer: str = 'rmsprop', 
           loss: str | any = None, 
           metrics: list[str | any] = None, 
           **kwargs)
```

### Par√°metros

- **`optimizer`**: Nombre del [optimizador](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), por defecto `'rmsprop'`. El optimizador ajusta los pesos del modelo bas√°ndose en el gradiente de la funci√≥n de p√©rdida. Existen varios optimizadores cada uno con sus ventajas y desventajas, algunos de ellos son:
  - **`RMSProp`**: Divide la tasa de aprendizaje por una media m√≥vil del tama√±o reciente de los gradientes.
  - **`AdaGrad`**: Adapta la tasa de aprendizaje seg√∫n la frecuencia de actualizaci√≥n de cada par√°metro.
  - **`Adam`**: Una combinaci√≥n de AdaGrad y RMSProp, ajusta din√°micamente la tasa de aprendizaje. Es vers√°til y se adapta bien a la mayor√≠a de los problemas.
  - **`SGD (Stochastic Gradient Descent)`**: Ajusta los pesos de manera incremental para cada muestra.

- **`loss`**: Nombre de la [funci√≥n de perdida](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Mide la diferencia entre las predicciones del modelo y los valores reales y sirve como gu√≠a para el optimizador para actualizar los pesos. Algunas de las funciones de p√©rdida son:
  - **`SparseCategoricalCrossentropy`**: Ideal para clasificaci√≥n multiclase con etiquetas enteras.
  - **`CategoricalCrossentropy`**: Similar, pero para etiquetas one-hot. Donde las etiquetas one-hot es una forma de representar clases de manera binaria, ejemplo: `A = [1, 0, 0]`, `B = [0, 1, 0]` y `c = [0, 0, 1]`.
  - **`BinaryCrossentropy`**: Para problemas de clasificaci√≥n binaria.

- **`metrics`**: Lista de [m√©tricas](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) que debe evaluar el modelo durante el entrenamiento y las pruebas. Entre ellas est√°n:
  - **`accuracy`**: Mide el porcentaje de predicciones correctas.
  - **`Precision, Recall, F1-Score`**: Miden la exactitud, la capacidad para identificar instancias relevantes y el balance entre precision y recall, respectivamente.

---

## **Funci√≥n 15** `image_dataset_from_directory`

```python
def image_dataset_from_directory(directory: any, 
                                labels: str = 'inferred', 
                                label_mode: str = 'int', 
                                color_mode: str = 'rgb', 
                                batch_size: int = 32, 
                                image_size: tuple[int, int] = (256, 256), 
                                seed: any = None, 
                                validation_split = None, 
                                subset: str = None, 
                                pad_to_aspect_ratio: bool = False, 
                                **kwargs)
```

### Par√°metros

- **`directory`**: Direcci√≥n de la carpeta que contiene los datos de entrenamiento.

- **`labels`**: Lista de etiquetas, por defecto `inferred`. Cuando es `inferred` las etiquetas se generan a partir de la estructura del directorio, cuando es `None` se indica que no hay etiquetas o simplemente le pasamos la lista de etiquetas.

- **`label_mode`**: Cadena que describe la codificaci√≥n de las etiquetas. Las opciones son:
  - **`int`**: Valor por defecto, significa que las etiquetas se codifican como n√∫meros enteros (por ejemplo, para `sparse_categorical_crossentropy` loss).
  - **`categorical`**: Significa que las etiquetas se codifican como un vector categ√≥rico (por ejemplo, para `categorical_crossentropy` loss).
  - **`binary`**: Significa que las etiquetas (s√≥lo puede haber 2) se codifican como escalares float32 con valores 0 o 1 (por ejemplo, para `binary_crossentropy`).
  - **`None`**: Sin etiquetas (√∫til para inferencia).

- **`color_mode`**: Cadena que indica en que espacio de color obtener las im√°genes, `rgb` es el valor por defecto. otros valores son `grayscale` y `rgba`.

- **`batch_size`**: Tama√±o de los lotes de datos. Por defecto es 32. Si es Ninguno, los datos no se agrupar√°n por lotes (el conjunto de datos producir√° muestras individuales). Sirve para mejorar la eficiencia en memoria y procesamiento, escalabilidad, entre otras ventajas. Tener lotes muy grandes no es ideal por el uso intensivo de la memoria, adem√°s, puede generar sobreajustes.

- **`image_size`**: Tama√±o al que se redimensionan las im√°genes una vez le√≠das, especificado como `(alto, ancho)`. Por defecto es `(256, 256)`. Dado que se procesan lotes de im√°genes que deben tener el mismo tama√±o, debe indicarse este valor.

- **`seed`**: Semilla aleatoria opcional para barajar y transformar las im√°genes. Esta semilla sirve para reproducibilidad, en caso de compartir el dataset se obtengan los mismos resultados.

- **`validation_split`**: Opcional, n√∫mero entre 0 y 1. Este n√∫mero indica que proporci√≥n del conjunto se tomar√° para datos de validaci√≥n.

- **`subset`**: Cadena opcional que indica el subconjunto de datos a devolver. S√≥lo se utiliza si `validation_split` est√° activado. Los valores posibles son:
  - **`training`**: Para obtener √∫nicamente los datos de entrenamiento.
  - **`validation`**: Para obtener √∫nicamente los datos para validaci√≥n.
  - **`both`**: Retorna una tupla con ambos conjuntos (validaci√≥n y entrenamiento).

- **`pad_to_aspect_ratio`**: Si es verdadero, redimensiona las im√°genes sin distorsi√≥n, rellenando las im√°genes con un color negro si el tama√±o de la imagen no es el que se indica.

---

## **Funci√≥n 16** `fit`

```python
def fit(x: ndarray | Tensor | dict | Dataset | PyDataset = None, 
       epochs: int = 1, 
       callbacks: list[Callback] = None, 
       validation_split: float = 0.0, 
       validation_data ndarray | Tensor | dict | Dataset | PyDataset = None, 
       **kwargs)
```

### Par√°metros

- **`x`**: Datos de entrada.

- **`epochs`**: N√∫mero entero que indica el n√∫mero de √©pocas para entrenar el modelo, por defecto 1. Una √©poca es una iteraci√≥n sobre la totalidad de los datos `x`. Se debe tener en cuenta que muchas √©pocas no siempre significan un mejor entrenamiento.

- **`callbacks`**: Lista opcional de [Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks?hl=en" \o "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks?hl=en) (funciones) a aplicar durante el entrenamiento. De entre ellas se usaron 3, las cuales son:
  - [**ModelCheckpoint**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint): Guarda el modelo en un archivo como punto de control, en alg√∫n intervalo. Con el par√°metro `save_best_only = True` le indicamos que solo guarde el modelo que ha obtenido el mejor rendimiento.
  - [**EarlyStopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping): Detiene el entrenamiento cuando una m√©trica supervisada ha dejado de mejorar. Por defecto monitorea la propiedad `val_loss` por defecto, con `patience = 15` se indica el n√∫mero de √©pocas sin mejora a esperar para detener el entrenamiento, y con `restore_best_weights = True` se indica que restaure los mejores pesos a partir de la √∫ltima √©poca con mejor valor.
  - [**CSVLogger**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger): Guarda los resultados de cada √©poca en un archivo csv.

- **`validation_split`**: N√∫mero entre 0 y 1, por defecto 0. Este n√∫mero indica que proporci√≥n del conjunto se tomar√° para datos de validaci√≥n, estos datos no formar√°n parte del entrenamiento (puede usarse este par√°metro para no dividir el dataset como en el paso anterior). Si se proporciona `validation_data`, este par√°metro ser√° ignorado.

- **`validation_data`**: Datos sobre los que se eval√∫a la p√©rdida y cualquier m√©trica del modelo al final de cada √©poca. El modelo no se entrenar√° con estos datos. Por lo tanto, tenga en cuenta el hecho de que la p√©rdida de validaci√≥n de los datos proporcionados utilizando `validation_split` o `validation_data` no se ve afectada por las capas de regularizaci√≥n como el ruido y el dropout.

---

> üìù **Nota**: Este documento contiene informaci√≥n de referencia para funciones de procesamiento de im√°genes (PIL, OpenCV) y capas de redes neuronales (TensorFlow/Keras).