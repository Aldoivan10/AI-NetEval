# ğŸ“š DocumentaciÃ³n de Funciones

## **FunciÃ³n 1** `Image.convert`

```python
def convert(mode: str | None = None, 
           matrix: tuple[float, ...] | None = None, 
           dither: Dither | None = None, 
           palette: Palette = Palette.WEB, 
           colors: int = 256) â†’ Image
```

### ParÃ¡metros

- **`mode`**: Este es el parÃ¡metro mÃ¡s importante y especifica a quÃ© **[modo de color](https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes)** quieres convertir la imagen.

- **`matrix`**: Es opcional y se puede utilizar para especificar una matriz de transformaciÃ³n personalizada. Generalmente, no se usa a menos que necesites una conversiÃ³n especÃ­fica y personalizada de color.

- **`dither`**: Controla la cantidad de dithering (difuminado de colores) aplicada durante la conversiÃ³n. [Los mÃ©todos disponibles](https://pillow.readthedocs.io/en/stable/reference/Image.html#dither-modes) son `Dither.NONE` o `Dither.FLOYDSTEINBERG` (por defecto). Tenga en cuenta que esto no se utiliza cuando se suministra la matriz.

- **`palette`**: Es opcional, relevante solo cuando se convierte a modo P (paleta de colores) debido a que define cÃ³mo se debe crear la paleta. [Las paletas](https://pillow.readthedocs.io/en/stable/reference/Image.html#palettes) disponibles son `Palette.WEB` o `Palette.ADAPTIVE`.

- **`colors`**: Es opcional y se usa para definir el nÃºmero de colores cuando se estÃ¡ convirtiendo a una imagen en modo paleta. Por defecto es 256.

---

## **FunciÃ³n 2** `bilateralFilter`

```python
def bilateralFilter(src: MatLike, 
                   d: int, 
                   sigmaColor: float, 
                   sigmaSpace: float) -> MatLike
```

### ParÃ¡metros

- **`src`**: ImÃ¡gen a aplicar filtro.

- **`d`**: DiÃ¡metro de cada vecindario de pÃ­xeles utilizado durante el filtrado. Si no es positivo, se calcula a partir de `sigmaSpace`.

- **`sigmaColor`**: Filtro sigma en el espacio de color. Un valor mayor de este parÃ¡metro significa que los colores mÃ¡s distantes dentro del vecindario del pÃ­xel se mezclarÃ¡n entre sÃ­, resultando en Ã¡reas mÃ¡s grandes de color semi-igual.

- **`sigmaSpace`**: Filtro sigma en el espacio de coordenadas. Un valor mayor de este parÃ¡metro significa que los pÃ­xeles mÃ¡s alejados se influirÃ¡n mutuamente, siempre que sus colores sean lo suficientemente cercanos. Cuando `d > 0`, especifica el tamaÃ±o del vecindario independientemente de `sigmaSpace`. De lo contrario, `d` es proporcional a `sigmaSpace`.

---

## **FunciÃ³n 3** `auto_canny`

```python
def auto_canny(image: MatLike, sigma: float = 0.33)
```

### ParÃ¡metros

- **`image`**: ImÃ¡gen a aplicar filtro.

- **`sigma`**: Argumento opcional, puede utilizarse para variar los umbrales porcentuales que se determinan basÃ¡ndose en estadÃ­sticas simples. Con valor por defecto de 0.33.

---

## **FunciÃ³n 4** `findContours`

```python
def findContours(image: MatLike, 
                mode: int, 
                method: int, 
                contours: Sequence[MatLike] | None = None, 
                hierarchy: MatLike | None = None, 
                offset: Point = (0,0))
```

### ParÃ¡metros

- **`image`**: Imagen donde se buscarÃ¡n los contornos.

- **`mode`**: El [modo de recuperaciÃ³n de contornos](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71) que define la jerarquÃ­a de los mismos. Los valores posibles son:
  - **`RETR_EXTERNAL`**: Este mÃ©todo recupera solo los contornos exteriores. Es Ãºtil cuando solo te interesa detectar los lÃ­mites externos de los objetos en la imagen, de modo que si hay un contorno que encierra a otro (como cÃ­rculos concÃ©ntricos), sÃ³lo se da el mÃ¡s exterior.
  - **`RETR_LIST`**: Este mÃ©todo recupera todos los contornos sin establecer relaciones jerÃ¡rquicas. Es Ãºtil cuando necesitas todos los contornos, pero no te importa la estructura jerÃ¡rquica entre ellos.
  - **`RETR_TREE`**: Este mÃ©todo recupera todos los contornos y reconstruye una jerarquÃ­a completa de contornos anidados. Es Ãºtil cuando necesitas entender la relaciÃ³n entre contornos internos y externos, como en la detecciÃ³n de objetos dentro de otros objetos.
  - **`RETR_CCOMP`**: Similar a `RETR_TREE`, pero solo crea relaciones jerÃ¡rquicas entre contornos de primer y segundo nivel. Es Ãºtil cuando necesitas una jerarquÃ­a limitada a dos niveles.

- **`method`**: El [mÃ©todo de aproximaciÃ³n de contornos](https://docs.opencv.org/4.x/d3/dc0/group__imgproc__shape.html#ga4303f45752694956374734a03c54d5ff) que define cÃ³mo se representan los contornos. Los valores posibles son:
  - **`CHAIN_APPROX_NONE`**: Guarda todos los puntos del contorno. Es la mÃ¡s precisa, pero puede generar muchos puntos, lo que aumenta el procesamiento.
  - **`CHAIN_APPROX_SIMPLE`**: Reduce la cantidad de puntos guardando solo los puntos esenciales que forman el contorno, eliminando los puntos redundantes. Esto simplifica mucho el contorno y es Ãºtil para la mayorÃ­a de los casos.
  - **`CHAIN_APPROX_TC89_L1`** y **`CHAIN_APPROX_TC89_KCOS`**: Son mÃ©todos de aproximaciÃ³n de contornos que utilizan el algoritmo de Teh-Chin, que proporciona una mayor precisiÃ³n y puede ser Ãºtil en casos especÃ­ficos donde se necesita una mayor exactitud.

- **`contours`**: Opcional. Una lista de contornos detectados, donde cada contorno es una lista de puntos. Si se proporciona, se llena con los contornos detectados.

- **`hierarchy`**: Opcional. Una matriz que describe la relaciÃ³n jerÃ¡rquica entre los contornos. Es Ãºtil para entender cÃ³mo se relacionan los contornos entre sÃ­ (por ejemplo, contornos internos dentro de contornos externos).

- **`offset`**: Opcional. Un desplazamiento para ajustar las coordenadas de los contornos. Ãštil si se estÃ¡ trabajando con recortes de imÃ¡genes y se necesita ajustar las coordenadas de los contornos a la imagen original.

---

## **FunciÃ³n 5** `four_point_transform`

```python
def four_point_transform(image: MatLike, pts: List[Point])
```

### ParÃ¡metros

- **`image`**: ImÃ¡gen a obtener sub-imÃ¡gen.

- **`pts`**: Lista de los 4 puntos que contienen la sub-imÃ¡gen deseada.

---

## **FunciÃ³n 6** `crop`

```python
def crop(box: tuple[float, float, float, float] | None = None)
```

### ParÃ¡metros

- **`box`**: Opcional, lista de coordenadas para hacer el recorte, el orden es `[x0, y0, x1, y1]`. Por defecto es `None`.

---

## **FunciÃ³n 7** `tf.keras.layers.Input`

```python
tf.keras.layers.Input(shape: tuple[int] = None, **kwargs)
```

### ParÃ¡metros

- **`shape`**: Opcional, tupla de enteros para definir la forma de las entradas. SÃ­ no se asigna, se interpretarÃ¡ que no se conoce las dimensiones y puede variar.

---

## **FunciÃ³n 8** Data augmented

### ParÃ¡metro comÃºn

- **`fill_value`**: Valor numÃ©rico entre 0 y 255 con el que se rellenarÃ¡n los lÃ­mites cuando se usa `constant` como mÃ©todo de relleno.

- **`fill_mode`**: Forma en que se rellenan los lÃ­mites segÃºn el modo dado, entre ellos:
  - **`reflect`**: Valor por defecto, refleja el borde del Ãºltimo pÃ­xel de la imagen para llenar los vacÃ­os.
  - **`constant`**: Los lÃ­mites se rellenan con un mismo valor (color) especificado por `fill_value`.
  - **`wrap`**: La entrada se extiende envolviendo hasta el borde opuesto.
  - **`nearest`**: La entrada se extiende por el pÃ­xel mÃ¡s cercano.

### `tf.keras.layers.RandomTranslation`

```python
tf.keras.layers.RandomTranslation(height_factor: float | tuple[float, float], 
                                 width_factor: float | tuple, 
                                 fill_mode: str = 'reflect', 
                                 fill_value: float = 0.0, 
                                 **kwargs)
```

#### ParÃ¡metros

- **`height_factor`**: Un nÃºmero o tupla de nÃºmeros con valores de entre 0 y 1, que representa el lÃ­mite inferior y superior para el desplazamiento vertical de manera porcentual. Un valor negativo significa desplazar la imagen hacia arriba, mientras que un valor positivo significa desplazarla hacia abajo. Si el factor es un nÃºmero, este se usarÃ¡ para ambos lÃ­mites. Ejemplo: `height_factor = .2` darÃ¡ como resultado `[-20%, +20%]`.

- **`width_factor`**: Un nÃºmero o tupla de nÃºmeros con valores de entre 0 y 1, que representa el lÃ­mite inferior y superior para el desplazamiento horizontal de manera porcentual. Un valor negativo significa desplazar la imagen hacia la izquierda, mientras que un valor positivo significa desplazarla hacia la derecha.

### `tf.keras.layers.RandomRotation`

```python
tf.keras.layers.RandomRotation(factor: float | tuple[float, float], 
                              fill_mode: str = 'reflect', 
                              fill_value: float = 0.0, 
                              **kwargs)
```

#### ParÃ¡metros

- **`factor`**: Un nÃºmero representado como fracciÃ³n de 2Ï€, o una tupla de tamaÃ±o 2 que representa los lÃ­mites inferior y superior de la rotaciÃ³n en sentido horario y antihorario. Un valor positivo significa girar en el sentido contrario a las agujas del reloj, mientras que uno negativo significa girar en el sentido de las agujas del reloj.

### `tf.keras.layers.RandomZoom`

```python
tf.keras.layers.RandomZoom(height_factor: float | tuple[float, float], 
                          fill_mode: str ='reflect', 
                          fill_value: float = 0.0, 
                          **kwargs)
```

#### ParÃ¡metros

- **`height_factor`**: Un nÃºmero representado como fracciÃ³n del valor, o una tupla de tamaÃ±o 2 que representa el lÃ­mite inferior y superior para el zoom (aumento) vertical. Cuando se representa como un Ãºnico nÃºmero, este valor se utiliza tanto para el lÃ­mite superior como para el inferior. Un valor positivo significa alejar, mientras que un valor negativo significa acercar.

### `tf.keras.layers.RandomBrightness`

```python
tf.keras.layers.RandomBrightness(factor: float | tuple[float, float], 
                                **kwargs)
```

#### ParÃ¡metros

- **`factor`**: NÃºmero o una lista/tupla de 2 nÃºmeros entre -1.0 y 1.0. El factor se utiliza para determinar el lÃ­mite inferior y superior del ajuste del brillo. Se elegirÃ¡ aleatoriamente un valor entre los lÃ­mites. Cuando se elige -1.0, la imagen de salida serÃ¡ negra, y cuando se elige 1.0, la imagen serÃ¡ totalmente blanca.

### `tf.keras.layers.RandomContrast`

```python
tf.keras.layers.RandomContrast(factor: float | tuple[float, float], 
                              **kwargs)
```

#### ParÃ¡metros

- **`factor`**: NÃºmero positivo representado como fracciÃ³n del valor, o una tupla de tamaÃ±o 2 que representa los lÃ­mites inferior y superior. Cuando se representa como un Ãºnico nÃºmero, este valor se utiliza tanto para el lÃ­mite superior como para el inferior. El factor de contraste se elegirÃ¡ aleatoriamente entre `[1.0 - inferior, 1.0 + superior]`. Para cualquier pÃ­xel `x` del canal, la salida serÃ¡ `(x - media) * factor + media`, donde `media` es el valor medio del canal.

---

## **FunciÃ³n 9** `tf.keras.layers.Rescaling`

```python
tf.keras.layers.Rescaling(scale: float, 
                         offset: float, 
                         **kwargs)
```

### ParÃ¡metros

- **`scale`**: La escala a aplicar a las entradas. Ejemplo: Para reescalar una entrada en el rango `[0, 255]` para que estÃ© en el rango `[0, 1]`, pasarÃ­a `scale = 1./255` y para reescalar una entrada en el rango `[0, 255]` para que estÃ© en el rango `[-1, 1]`, se pasarÃ­a `scale = 1./127.5` y `offset = -1`.

- **`offset`**: El desplazamiento a aplicar a las entradas.

---

## **FunciÃ³n 10** `tf.keras.layers.Conv2D`

```python
tf.keras.layers.Conv2D(filters: int, 
                      kernel_size: int | tuple[int, int], 
                      activation: str | any, 
                      **kwargs)
```

### ParÃ¡metros

- **`filters`**: NÃºmero de filtros. Cada filtro representa una caracterÃ­stica que puede variar desde bordes y texturas hasta patrones mÃ¡s complejos; a mayor cantidad de filtros, el modelo puede aprender caracterÃ­sticas mÃ¡s detalladas, aunque con un mayor costo computacional.

- **`kernel_size`**: TamaÃ±o del filtro (ancho y alto), que determina el "vecindario" de la entrada que cada filtro abarca en cada paso. SÃ­ solo se pasa un Ãºnico valor, se usarÃ¡ el mismo para el ancho y alto. Los filtros pequeÃ±os (como 3x3) son comunes, ya que capturan bien los patrones locales y mantienen el costo computacional bajo.

- **`activation`**: FunciÃ³n de activaciÃ³n, que define cÃ³mo se manejarÃ¡n los valores en cada paso. Entre las opciones, se encuentran `relu`, `leaky relu`, entre otras.

---

## **FunciÃ³n 11** `tf.keras.layers.MaxPool2D`

```python
tf.keras.layers.MaxPool2D(pool_size: int | tuple[int, int] = (2, 2), 
                         **kwargs)
```

### ParÃ¡metros

- **`pool_size`**: NÃºmero entero o tupla de 2 enteros, factores por los que reducir la escala `(dim1, dim2)`. Si sÃ³lo se especifica un entero, se utilizarÃ¡ la misma longitud de ventana para todas las dimensiones.

---

## **FunciÃ³n 12** `tf.keras.layers.Dense`

```python
tf.keras.layers.Dense(units: int, 
                     activation str | any = None, 
                     **kwargs)
```

### ParÃ¡metros

- **`units`**: NÃºmero entero positivo, para indicar el nÃºmero de neuronas que tendrÃ¡ la capa.

- **`activation`**: FunciÃ³n de activaciÃ³n.

---

## **FunciÃ³n 13** `tf.keras.layers.Dropout`

```python
tf.keras.layers.Dropout(rate: float, **kwargs)
```

### ParÃ¡metros

- **`rate`**: NÃºmero entre 0 y 1. FracciÃ³n de las unidades de entrada que hay que dejar caer.

---

## **FunciÃ³n 14** `compile`

```python
def compile(optimizer: str = 'rmsprop', 
           loss: str | any = None, 
           metrics: list[str | any] = None, 
           **kwargs)
```

### ParÃ¡metros

- **`optimizer`**: Nombre del [optimizador](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), por defecto `'rmsprop'`. El optimizador ajusta los pesos del modelo basÃ¡ndose en el gradiente de la funciÃ³n de pÃ©rdida. Existen varios optimizadores cada uno con sus ventajas y desventajas, algunos de ellos son:
  - **`RMSProp`**: Divide la tasa de aprendizaje por una media mÃ³vil del tamaÃ±o reciente de los gradientes.
  - **`AdaGrad`**: Adapta la tasa de aprendizaje segÃºn la frecuencia de actualizaciÃ³n de cada parÃ¡metro.
  - **`Adam`**: Una combinaciÃ³n de AdaGrad y RMSProp, ajusta dinÃ¡micamente la tasa de aprendizaje. Es versÃ¡til y se adapta bien a la mayorÃ­a de los problemas.
  - **`SGD (Stochastic Gradient Descent)`**: Ajusta los pesos de manera incremental para cada muestra.

- **`loss`**: Nombre de la [funciÃ³n de perdida](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Mide la diferencia entre las predicciones del modelo y los valores reales y sirve como guÃ­a para el optimizador para actualizar los pesos. Algunas de las funciones de pÃ©rdida son:
  - **`SparseCategoricalCrossentropy`**: Ideal para clasificaciÃ³n multiclase con etiquetas enteras.
  - **`CategoricalCrossentropy`**: Similar, pero para etiquetas one-hot. Donde las etiquetas one-hot es una forma de representar clases de manera binaria, ejemplo: `A = [1, 0, 0]`, `B = [0, 1, 0]` y `c = [0, 0, 1]`.
  - **`BinaryCrossentropy`**: Para problemas de clasificaciÃ³n binaria.

- **`metrics`**: Lista de [mÃ©tricas](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) que debe evaluar el modelo durante el entrenamiento y las pruebas. Entre ellas estÃ¡n:
  - **`accuracy`**: Mide el porcentaje de predicciones correctas.
  - **`Precision, Recall, F1-Score`**: Miden la exactitud, la capacidad para identificar instancias relevantes y el balance entre precision y recall, respectivamente.

---

## **FunciÃ³n 15** `image_dataset_from_directory`

```python
def image_dataset_from_directory(directory: any, 
                                labels: str = 'inferred', 
                                label_mode: str = 'int', 
                                color_mode: str = 'rgb', 
                                batch_size: int = 32, 
                                image_size: tuple[int, int] = (256, 256), 
                                seed: any = None, 
                                validation_split = None, 
                                subset: str = None, 
                                pad_to_aspect_ratio: bool = False, 
                                **kwargs)
```

### ParÃ¡metros

- **`directory`**: DirecciÃ³n de la carpeta que contiene los datos de entrenamiento.

- **`labels`**: Lista de etiquetas, por defecto `inferred`. Cuando es `inferred` las etiquetas se generan a partir de la estructura del directorio, cuando es `None` se indica que no hay etiquetas o simplemente le pasamos la lista de etiquetas.

- **`label_mode`**: Cadena que describe la codificaciÃ³n de las etiquetas. Las opciones son:
  - **`int`**: Valor por defecto, significa que las etiquetas se codifican como nÃºmeros enteros (por ejemplo, para `sparse_categorical_crossentropy` loss).
  - **`categorical`**: Significa que las etiquetas se codifican como un vector categÃ³rico (por ejemplo, para `categorical_crossentropy` loss).
  - **`binary`**: Significa que las etiquetas (sÃ³lo puede haber 2) se codifican como escalares float32 con valores 0 o 1 (por ejemplo, para `binary_crossentropy`).
  - **`None`**: Sin etiquetas (Ãºtil para inferencia).

- **`color_mode`**: Cadena que indica en que espacio de color obtener las imÃ¡genes, `rgb` es el valor por defecto. otros valores son `grayscale` y `rgba`.

- **`batch_size`**: TamaÃ±o de los lotes de datos. Por defecto es 32. Si es Ninguno, los datos no se agruparÃ¡n por lotes (el conjunto de datos producirÃ¡ muestras individuales). Sirve para mejorar la eficiencia en memoria y procesamiento, escalabilidad, entre otras ventajas. Tener lotes muy grandes no es ideal por el uso intensivo de la memoria, ademÃ¡s, puede generar sobreajustes.

- **`image_size`**: TamaÃ±o al que se redimensionan las imÃ¡genes una vez leÃ­das, especificado como `(alto, ancho)`. Por defecto es `(256, 256)`. Dado que se procesan lotes de imÃ¡genes que deben tener el mismo tamaÃ±o, debe indicarse este valor.

- **`seed`**: Semilla aleatoria opcional para barajar y transformar las imÃ¡genes. Esta semilla sirve para reproducibilidad, en caso de compartir el dataset se obtengan los mismos resultados.

- **`validation_split`**: Opcional, nÃºmero entre 0 y 1. Este nÃºmero indica que proporciÃ³n del conjunto se tomarÃ¡ para datos de validaciÃ³n.

- **`subset`**: Cadena opcional que indica el subconjunto de datos a devolver. SÃ³lo se utiliza si `validation_split` estÃ¡ activado. Los valores posibles son:
  - **`training`**: Para obtener Ãºnicamente los datos de entrenamiento.
  - **`validation`**: Para obtener Ãºnicamente los datos para validaciÃ³n.
  - **`both`**: Retorna una tupla con ambos conjuntos (validaciÃ³n y entrenamiento).

- **`pad_to_aspect_ratio`**: Si es verdadero, redimensiona las imÃ¡genes sin distorsiÃ³n, rellenando las imÃ¡genes con un color negro si el tamaÃ±o de la imagen no es el que se indica.

---

## **FunciÃ³n 16** `fit`

```python
def fit(x: ndarray | Tensor | dict | Dataset | PyDataset = None, 
       epochs: int = 1, 
       callbacks: list[Callback] = None, 
       validation_split: float = 0.0, 
       validation_data ndarray | Tensor | dict | Dataset | PyDataset = None, 
       **kwargs)
```

### ParÃ¡metros

- **`x`**: Datos de entrada.

- **`epochs`**: NÃºmero entero que indica el nÃºmero de Ã©pocas para entrenar el modelo, por defecto 1. Una Ã©poca es una iteraciÃ³n sobre la totalidad de los datos `x`. Se debe tener en cuenta que muchas Ã©pocas no siempre significan un mejor entrenamiento.

- **`callbacks`**: Lista opcional de [Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks?hl=en" \o "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks?hl=en) (funciones) a aplicar durante el entrenamiento. De entre ellas se usaron 3, las cuales son:
  - [**ModelCheckpoint**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint): Guarda el modelo en un archivo como punto de control, en algÃºn intervalo. Con el parÃ¡metro `save_best_only = True` le indicamos que solo guarde el modelo que ha obtenido el mejor rendimiento.
  - [**EarlyStopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping): Detiene el entrenamiento cuando una mÃ©trica supervisada ha dejado de mejorar. Por defecto monitorea la propiedad `val_loss` por defecto, con `patience = 15` se indica el nÃºmero de Ã©pocas sin mejora a esperar para detener el entrenamiento, y con `restore_best_weights = True` se indica que restaure los mejores pesos a partir de la Ãºltima Ã©poca con mejor valor.
  - [**CSVLogger**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CSVLogger): Guarda los resultados de cada Ã©poca en un archivo csv.

- **`validation_split`**: NÃºmero entre 0 y 1, por defecto 0. Este nÃºmero indica que proporciÃ³n del conjunto se tomarÃ¡ para datos de validaciÃ³n, estos datos no formarÃ¡n parte del entrenamiento (puede usarse este parÃ¡metro para no dividir el dataset como en el paso anterior). Si se proporciona `validation_data`, este parÃ¡metro serÃ¡ ignorado.

- **`validation_data`**: Datos sobre los que se evalÃºa la pÃ©rdida y cualquier mÃ©trica del modelo al final de cada Ã©poca. El modelo no se entrenarÃ¡ con estos datos. Por lo tanto, tenga en cuenta el hecho de que la pÃ©rdida de validaciÃ³n de los datos proporcionados utilizando `validation_split` o `validation_data` no se ve afectada por las capas de regularizaciÃ³n como el ruido y el dropout.

---

> ğŸ“ **Nota**: Este documento contiene informaciÃ³n de referencia para funciones de procesamiento de imÃ¡genes (PIL, OpenCV) y capas de redes neuronales (TensorFlow/Keras).